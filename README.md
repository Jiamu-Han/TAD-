本科生毕业设计期间学习的一些TAD视频时序动作检测相关的顶会期刊，作以文献精读和复现学习。
/During my undergraduate graduation project, I studied temporal action detection (TAD) by closely reading and reproducing representative papers from top-tier conferences and journals.
<img width="1200" height="896" alt="c74faffe25f8ae37fadbf94f8e776487" src="https://github.com/user-attachments/assets/9b52d52e-7d69-4ae3-a890-33e06b4e9cf6" />
参考文献
1. Simonyan K, Zisserman A. Two-stream convolutional networks for action recognition in videos[J]. Advances in neural information processing systems, 2014, 27.
2. Fang Z, Yu J, Hong R. Boundary Discretization and Reliable Classification Network for Temporal Action Detection[J]. IEEE Transactions on Multimedia, 2025.
3. Liu X, Wang Q, Hu Y, et al. End-to-end temporal action detection with transformer[J]. IEEE Transactions on Image Processing, 2022, 31: 5427-5441.
4. Kim H J, Lee Y, Hong J H, et al. DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer[C]//Proceedings of the Computer Vision and Pattern Recognition Conference. 2025: 24286-24296.
5. Kim J, Lee M, Heo J P. Self-feedback detr for temporal action detection[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023: 10286-10296.
6. Shi D, Zhong Y, Cao Q, et al. Tridet: Temporal action detection with relative boundary modeling[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 18857-18866.
7. Nag S, Zhu X, Deng J, et al. Difftad: Temporal action detection with proposal denoising diffusion[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023: 10362-10374.
8. Yang M, Chen G, Zheng Y D, et al. Basictad: an astounding rgb-only baseline for temporal action detection[J]. Computer Vision and Image Understanding, 2023, 232: 103692.
9. Li Y L, Wu X, Liu X, et al. From isolated islands to pangea: Unifying semantic space for human action understanding[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024: 16582-16592.
10. Kim J, Lee M, Heo J P. Long-term pre-training for temporal action detection with transformers[J]. Pattern Recognition, 2025: 112144.
11. Zhu X, Zhu Y, Chen T, et al. FDDet: Frequency-Decoupling for Boundary Refinement in Temporal Action Detection[C]//International Conference on Intelligent Computing. Singapore: Springer Nature Singapore, 2025: 205-217.
12. Khan S, Hassan A, Hussain F, et al. Enhanced spatial stream of two-stream network using optical flow for human action recognition[J]. Applied Sciences, 2023, 13(14): 8003.
13. Li Q, Liu D, Zu G, et al. Multigranularity Feature Aggregation and Cross-level Boundary Modeling for Temporal Action Detection[J]. ACM Transactions on Multimedia Computing, Communications and Applications, 2025, 21(3): 1-24.
14. Liu S, Zhao C, Zohra F, et al. Opentad: A unified framework and comprehensive study of temporal action detection[C]//Proceedings of the Computer Vision and Pattern Recognition Conference. 2025: 2625-2635.
15. Yang L, Zheng Z, Han Y, et al. Dyfadet: Dynamic feature aggregation for temporal action detection[C]//European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024: 305-322.
16. Kwon D, Kim I, Kwak S. Boosting Semi-Supervised Video Action Detection with Temporal Context[C]//2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). IEEE, 2025: 847-858.
17. Caba Heilbron F, Escorcia V, Ghanem B, et al. Activitynet: A large-scale video benchmark for human activity understanding[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 961-970.
18. Lin T, Liu X, Li X, et al. BMN: Boundary-matching network for temporal action proposal generation[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019: 3889-3898.
19. Zhang C L, Wu J, Li Y. Actionformer: Localizing moments of actions with transformers[C]//European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022: 492-510.
20. Radford A, Kim J W, Hallacy C, et al. Learning transferable visual models from natural language supervision[C]//International Conference on Machine Learning. PMLR, 2021: 8748-8763.
21. Wang M, Xing J, Liu Y. Actionclip: A new paradigm for video action recognition[J]. arXiv preprint arXiv:2109.08472, 2021.
22. Jiang Y G, Liu J, Zamir A R, et al. THUMOS challenge: Action recognition with a large number of classes[EB/OL]. (2014-09).
23. Zhu X, Su W, Lu L, et al. Deformable detr: Deformable transformers for end-to-end object detection[J]. arXiv preprint arXiv:2010.04159, 2020.
24. Carreira J, Zisserman A. Quo vadis, action recognition? a new model and the kinetics dataset[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 6299-6308.
25. Feichtenhofer C, Fan H, Malik J, et al. Slowfast networks for video recognition[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019: 6202-6211.
26. Carion N, Massa F, Synnaeve G, et al. End-to-end object detection with transformers[C]//European Conference on Computer Vision. Cham: Springer International Publishing, 2020: 213-229.
